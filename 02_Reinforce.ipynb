{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/RL/blob/35-Study-Doc-Custom_grid_world/02_Reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MLB979Vs-2J1"
      },
      "id": "MLB979Vs-2J1"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b 35-Study-Doc-Custom_grid_world https://github.com/merucode/RL.git\n",
        "!cd RL && mv * ../"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bMkFjiRc-i71",
        "outputId": "ea1e08fa-54bc-44bd-926a-46c47f394542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bMkFjiRc-i71",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RL'...\n",
            "remote: Enumerating objects: 201, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 201 (delta 47), reused 0 (delta 0), pack-reused 80\u001b[K\n",
            "Receiving objects: 100% (201/201), 11.42 MiB | 5.76 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e gym-examples"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-ddm_fdzWtRI",
        "outputId": "39fb797c-d8c4-4a2a-8213-82d7a5f623d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "id": "-ddm_fdzWtRI",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/gym-examples\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym==0.26.0 (from gym-examples==0.0.1)\n",
            "  Downloading gym-0.26.0.tar.gz (710 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m710.3/710.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym-examples==0.0.1)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.0->gym-examples==0.0.1) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.0->gym-examples==0.0.1) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.0->gym-examples==0.0.1) (0.0.8)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.0-py3-none-any.whl size=826275 sha256=8559d964befd9b4e09df87cbe477e46405b10474e73a79df39c9a503de936105\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/da/7c/a034980e59e34687bfb6cfa3a5f3e9b389264a0c59519c59fa\n",
            "Successfully built gym\n",
            "Installing collected packages: pygame, gym, gym-examples\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.0\n",
            "    Uninstalling pygame-2.5.0:\n",
            "      Successfully uninstalled pygame-2.5.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py develop for gym-examples\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.26.0 gym-examples-0.0.1 pygame-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE: After inistall gym-examples, Restart runtime"
      ],
      "metadata": {
        "id": "aI9PkFlbBds1"
      },
      "id": "aI9PkFlbBds1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lyric-aruba",
      "metadata": {
        "id": "lyric-aruba"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "durable-english",
      "metadata": {
        "scrolled": true,
        "id": "durable-english",
        "outputId": "1143b91b-9e53-4ac3-ee75-ca9e52012bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-2-74f018fa4af7>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<cell line: 1>\u001b[0m\n    env = gym.make(\"gym_examples:gym_examples/GridWorld-v0\")\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m581\u001b[0m, in \u001b[1;35mmake\u001b[0m\n    env_creator = load(spec_.entry_point)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\"\u001b[0m, line \u001b[1;32m61\u001b[0m, in \u001b[1;35mload\u001b[0m\n    mod = importlib.import_module(mod_name)\n",
            "  File \u001b[1;32m\"/usr/lib/python3.10/importlib/__init__.py\"\u001b[0m, line \u001b[1;32m126\u001b[0m, in \u001b[1;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m1050\u001b[0m, in \u001b[1;35m_gcd_import\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m1027\u001b[0m, in \u001b[1;35m_find_and_load\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m1006\u001b[0m, in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m688\u001b[0m, in \u001b[1;35m_load_unlocked\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m883\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m241\u001b[0m, in \u001b[1;35m_call_with_frames_removed\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/gym-examples/gym_examples/envs/__init__.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from gym_examples.envs.grid_world import GridWorldEnv\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/gym-examples/gym_examples/envs/grid_world.py\"\u001b[0;36m, line \u001b[0;32m91\u001b[0m\n\u001b[0;31m    terminated = np.array_equal(self._agent_location, self._target_location\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"gym_examples:gym_examples/GridWorld-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single env\n",
        "print(f'observation space : {env.observation_space}')\n",
        "print(f'action space      : {env.action_space}')\n",
        "print(f'action shape      : {env.action_space.n}')"
      ],
      "metadata": {
        "id": "psH2NxXJSn0t",
        "outputId": "22c0479f-5d8f-4620-a757-4ed621916ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "psH2NxXJSn0t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation space : Dict('agent': Box(0, 4, (2,), int64), 'target': Box(0, 4, (2,), int64))\n",
            "action space      : Discrete(4)\n",
            "action shape      : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs, _ = env.reset()\n",
        "print(obs)\n",
        "\n",
        "obs = np.hstack((obs['agent'], obs['target']))\n",
        "print(obs)"
      ],
      "metadata": {
        "id": "dUs-ATpNAioL",
        "outputId": "250754fa-f6e8-4514-8ae8-71f7486244dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dUs-ATpNAioL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': array([4, 2]), 'target': array([1, 2])}\n",
            "[4 2 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = env.action_space.sample()\n",
        "env.step(0)"
      ],
      "metadata": {
        "id": "mN26BJZZBlOa",
        "outputId": "479215fe-a9e4-4cea-d374-50495301c558",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mN26BJZZBlOa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'agent': array([3, 2]), 'target': array([3, 0])},\n",
              " 0,\n",
              " False,\n",
              " False,\n",
              " {'distance': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforce model"
      ],
      "metadata": {
        "id": "RiQvgCB7TcxS"
      },
      "id": "RiQvgCB7TcxS"
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import numpy as np\n",
        "\n",
        "#Device\n",
        "device = device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.0002\n",
        "gamma         = 0.98\n",
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Policy, self).__init__()\n",
        "        self.data = []\n",
        "\n",
        "        self.fc1 = nn.Linear(4, 128)\n",
        "        self.fc2 = nn.Linear(128, 4)\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.softmax(self.fc2(x), dim=0)\n",
        "        return x\n",
        "\n",
        "    def put_data(self, item):\n",
        "        self.data.append(item)\n",
        "\n",
        "    def train_net(self):\n",
        "        R = 0\n",
        "        self.optimizer.zero_grad()\n",
        "        for r, prob in self.data[::-1]:\n",
        "            R = r + gamma * R\n",
        "            loss = -torch.log(prob) * R\n",
        "            loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.data = []"
      ],
      "metadata": {
        "id": "Oh3nQK_aTkOh"
      },
      "id": "Oh3nQK_aTkOh",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    #env = gym.make('CartPole-v1')\n",
        "    env = gym.make(\"gym_examples:gym_examples/GridWorld-v0\")\n",
        "    pi = Policy()\n",
        "    score = 0.0\n",
        "    max_score = 0\n",
        "    print_interval = 100\n",
        "\n",
        "    pi.to(device)\n",
        "\n",
        "    for n_epi in range(6000):\n",
        "        #s, _ = env.reset()\n",
        "        obs, _ = env.reset()\n",
        "        s = np.hstack((obs['agent'], obs['target']))\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            prob = pi(torch.from_numpy(s).float().to(device))\n",
        "            m = Categorical(prob)\n",
        "            a = m.sample()\n",
        "            obs_next, r, done, truncated, info = env.step(a.item())\n",
        "            s_prime =  np.hstack((obs_next['agent'], obs_next['target']))\n",
        "            pi.put_data((r,prob[a]))\n",
        "            s = s_prime\n",
        "            score += r\n",
        "\n",
        "        pi.train_net()\n",
        "\n",
        "        if n_epi%print_interval==0 and n_epi!=0:\n",
        "            print(\"# of episode :{}, avg score : {}\".format(n_epi, score/print_interval))\n",
        "            if score > max_score:\n",
        "                torch.save(pi.state_dict(), 'model_weights.pth')\n",
        "                print(f\"# max score : {score/print_interval}, and save model_weights.pth\")\n",
        "                max_score = score\n",
        "            score = 0.0\n",
        "\n",
        "    env.close()"
      ],
      "metadata": {
        "id": "tX3eFo7vYMXi"
      },
      "id": "tX3eFo7vYMXi",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_jfTqHMOZNta",
        "outputId": "225d183a-7544-41ee-8b4a-055c0b7e96da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_jfTqHMOZNta",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of episode :100, avg score : 0.3325999999999773\n",
            "# max score : 0.3325999999999773, and save model_weights.pth\n",
            "# of episode :200, avg score : 0.44220000000000603\n",
            "# max score : 0.44220000000000603, and save model_weights.pth\n",
            "# of episode :300, avg score : 0.5127000000000118\n",
            "# max score : 0.5127000000000118, and save model_weights.pth\n",
            "# of episode :400, avg score : 0.5923000000000227\n",
            "# max score : 0.5923000000000227, and save model_weights.pth\n",
            "# of episode :500, avg score : 0.6982000000000076\n",
            "# max score : 0.6982000000000076, and save model_weights.pth\n",
            "# of episode :600, avg score : 0.7230000000000152\n",
            "# max score : 0.7230000000000152, and save model_weights.pth\n",
            "# of episode :700, avg score : 0.7556999999999993\n",
            "# max score : 0.7556999999999993, and save model_weights.pth\n",
            "# of episode :800, avg score : 0.7750999999999942\n",
            "# max score : 0.7750999999999942, and save model_weights.pth\n",
            "# of episode :900, avg score : 0.8051999999999896\n",
            "# max score : 0.8051999999999896, and save model_weights.pth\n",
            "# of episode :1000, avg score : 0.8267999999999992\n",
            "# max score : 0.8267999999999992, and save model_weights.pth\n",
            "# of episode :1100, avg score : 0.8170999999999919\n",
            "# of episode :1200, avg score : 0.8498999999999848\n",
            "# max score : 0.8498999999999848, and save model_weights.pth\n",
            "# of episode :1300, avg score : 0.8350999999999965\n",
            "# of episode :1400, avg score : 0.8643999999999921\n",
            "# max score : 0.8643999999999921, and save model_weights.pth\n",
            "# of episode :1500, avg score : 0.8694999999999904\n",
            "# max score : 0.8694999999999904, and save model_weights.pth\n",
            "# of episode :1600, avg score : 0.8445999999999949\n",
            "# of episode :1700, avg score : 0.879299999999988\n",
            "# max score : 0.879299999999988, and save model_weights.pth\n",
            "# of episode :1800, avg score : 0.8585999999999899\n",
            "# of episode :1900, avg score : 0.8757999999999907\n",
            "# of episode :2000, avg score : 0.853899999999992\n",
            "# of episode :2100, avg score : 0.8905999999999866\n",
            "# max score : 0.8905999999999866, and save model_weights.pth\n",
            "# of episode :2200, avg score : 0.8854999999999924\n",
            "# of episode :2300, avg score : 0.8682999999999886\n",
            "# of episode :2400, avg score : 0.885599999999992\n",
            "# of episode :2500, avg score : 0.8758999999999899\n",
            "# of episode :2600, avg score : 0.8987999999999894\n",
            "# max score : 0.8987999999999894, and save model_weights.pth\n",
            "# of episode :2700, avg score : 0.8897999999999905\n",
            "# of episode :2800, avg score : 0.9002999999999863\n",
            "# max score : 0.9002999999999863, and save model_weights.pth\n",
            "# of episode :2900, avg score : 0.8976999999999901\n",
            "# of episode :3000, avg score : 0.9049999999999939\n",
            "# max score : 0.9049999999999939, and save model_weights.pth\n",
            "# of episode :3100, avg score : 0.9050999999999951\n",
            "# max score : 0.9050999999999951, and save model_weights.pth\n",
            "# of episode :3200, avg score : 0.9001999999999936\n",
            "# of episode :3300, avg score : 0.910399999999988\n",
            "# max score : 0.910399999999988, and save model_weights.pth\n",
            "# of episode :3400, avg score : 0.9143999999999888\n",
            "# max score : 0.9143999999999888, and save model_weights.pth\n",
            "# of episode :3500, avg score : 0.9122999999999934\n",
            "# of episode :3600, avg score : 0.8906999999999846\n",
            "# of episode :3700, avg score : 0.9154999999999918\n",
            "# max score : 0.9154999999999918, and save model_weights.pth\n",
            "# of episode :3800, avg score : 0.9017999999999894\n",
            "# of episode :3900, avg score : 0.9264999999999926\n",
            "# max score : 0.9264999999999926, and save model_weights.pth\n",
            "# of episode :4000, avg score : 0.9187999999999913\n",
            "# of episode :4100, avg score : 0.9240999999999913\n",
            "# of episode :4200, avg score : 0.9156999999999909\n",
            "# of episode :4300, avg score : 0.9136999999999895\n",
            "# of episode :4400, avg score : 0.9068999999999913\n",
            "# of episode :4500, avg score : 0.9033999999999928\n",
            "# of episode :4600, avg score : 0.911399999999994\n",
            "# of episode :4700, avg score : 0.8954999999999924\n",
            "# of episode :4800, avg score : 0.9144999999999938\n",
            "# of episode :4900, avg score : 0.9337999999999924\n",
            "# max score : 0.9337999999999924, and save model_weights.pth\n",
            "# of episode :5000, avg score : 0.9205999999999901\n",
            "# of episode :5100, avg score : 0.9274999999999933\n",
            "# of episode :5200, avg score : 0.9342999999999927\n",
            "# max score : 0.9342999999999927, and save model_weights.pth\n",
            "# of episode :5300, avg score : 0.9285999999999955\n",
            "# of episode :5400, avg score : 0.9315999999999892\n",
            "# of episode :5500, avg score : 0.9374999999999943\n",
            "# max score : 0.9374999999999943, and save model_weights.pth\n",
            "# of episode :5600, avg score : 0.9273999999999948\n",
            "# of episode :5700, avg score : 0.9358999999999935\n",
            "# of episode :5800, avg score : 0.9352999999999945\n",
            "# of episode :5900, avg score : 0.9406999999999931\n",
            "# max score : 0.9406999999999931, and save model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Render"
      ],
      "metadata": {
        "id": "2qvB2V1WWOPJ"
      },
      "id": "2qvB2V1WWOPJ"
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('gym_examples:gym_examples/GridWorld-v0')\n",
        "\n",
        "video_every=1\n",
        "\n",
        "# define a trigger function, return True to start recording a new video:\n",
        "episode_trigger=lambda episode_id: ((episode_id)%video_every==0)\n",
        "\n",
        "# decorate env with a video recorder:\n",
        "env = gym.wrappers.RecordVideo(env, \"./video\", episode_trigger=episode_trigger, video_length=100000)\n",
        "\n",
        "def model_render():\n",
        "\n",
        "    pi = Policy()\n",
        "    pi.load_state_dict(torch.load('model_weights.pth'))\n",
        "    pi.eval()\n",
        "    pi.to(device)\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    s = np.hstack((obs['agent'], obs['target']))\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    while not done:\n",
        "            prob = pi(torch.from_numpy(s).float().to(device).to(device))\n",
        "            m = Categorical(prob)\n",
        "            a = m.sample()\n",
        "            obs_next, r, done, truncated, info = env.step(a.item())\n",
        "            s_prime =  np.hstack((obs_next['agent'], obs_next['target']))\n",
        "            score += r\n",
        "        #print(f'# test episode {episode} score : {score}')\n",
        "    env.close()\n",
        "\n",
        "    # while not done:\n",
        "    #     a = q.sample_action(torch.from_numpy(s).float(), epsilon=0)\n",
        "    #     s_prime, r, done, _ = env.step(a)\n",
        "    #     done_mask = 0.0 if done else 1.0\n",
        "    #     s = s_prime\n",
        "    #     score += r\n",
        "\n",
        "    # print(score)\n",
        "    # env.close()"
      ],
      "metadata": {
        "id": "M--qrKR5dcJr",
        "outputId": "9f9696fe-b1e8-4349-f675-f3a72dd13b27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "M--qrKR5dcJr",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_render()"
      ],
      "metadata": {
        "id": "du4xhh4xd5vi",
        "outputId": "151d4aff-c6b5-4241-ad05-b7e5611b61a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "du4xhh4xd5vi",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:59: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <TimeLimit<OrderEnforcing<PassiveEnvChecker<GridWorldEnv<gym_examples/GridWorld-v0>>>>> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.wrappers import RecordVideo\n",
        "\n",
        "#env = gym.make('CartPole-v1')\n",
        "\n",
        "video_every=1\n",
        "\n",
        "# define a trigger function, return True to start recording a new video:\n",
        "episode_trigger=lambda episode_id: ((episode_id)%video_every==0)\n",
        "# episode_trigger=lambda e: True\n",
        "# decorate env with a video recorder:\n",
        "#env = gym.wrappers.RecordVideo(env, \"./video\", episode_trigger=episode_trigger, video_length=100000)\n",
        "\n",
        "#Device\n",
        "device = device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def test_env(env_name, policy):\n",
        "    env = gym.make(env_name)\n",
        "\n",
        "    video_every=1\n",
        "    episode_trigger=lambda episode_id: ((episode_id)%video_every==0)\n",
        "    env = RecordVideo(env, \"./video\", episode_trigger=episode_trigger)\n",
        "    pi = policy\n",
        "    pi.load_state_dict(torch.load('model_weights.pth'))\n",
        "    pi.eval()\n",
        "    pi.to(device)\n",
        "\n",
        "    for episode in range(10):\n",
        "        obs, _ = env.reset()\n",
        "        s = np.hstack((obs['agent'], obs['target']))\n",
        "        score = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            prob = pi(torch.from_numpy(s).float().to(device).to(device))\n",
        "            m = Categorical(prob)\n",
        "            a = m.sample()\n",
        "            obs_next, r, done, truncated, info = env.step(a.item())\n",
        "            s_prime =  np.hstack((obs_next['agent'], obs_next['target']))\n",
        "            score += r\n",
        "        print(f'# test episode {episode} score : {score}')\n",
        "    env.close()\n",
        "    #del env\n"
      ],
      "metadata": {
        "id": "xHEIOUWIaZRh"
      },
      "id": "xHEIOUWIaZRh",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gym.wrappers import RecordVideo\n",
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "\n",
        "# def test_env(env_name, policy): #, obs_rms\n",
        "#     env = gym.make(env_name)\n",
        "#     env = RecordVideo(env, 'videos', episode_trigger=lambda e: True)\n",
        "#     pi = policy\n",
        "#     pi.to(device)\n",
        "\n",
        "#     for episode in range(10):\n",
        "#         obs, _ = env.reset()\n",
        "#         s = np.hstack((obs['agent'], obs['target']))\n",
        "#         score = 0\n",
        "#         done = False\n",
        "\n",
        "#         while not done:\n",
        "#             prob = pi(torch.from_numpy(s).float().to(device))\n",
        "#             m = Categorical(prob)\n",
        "#             a = m.sample()\n",
        "#             obs_next, r, done, truncated, info = env.step(a.item())\n",
        "#             s_prime =  np.hstack((obs_next['agent'], obs_next['target']))\n",
        "#             score += r\n",
        "#         print(f'episode {episode} score : {score}')\n",
        "#     del env"
      ],
      "metadata": {
        "id": "nlGbxiHtbZG_"
      },
      "id": "nlGbxiHtbZG_",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_env(\"gym_examples:gym_examples/GridWorld-v0\", Policy())"
      ],
      "metadata": {
        "id": "NEX3AkPRc7mp",
        "outputId": "7a75b58f-59b3-42ae-a36f-51812c799607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NEX3AkPRc7mp",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# test episode 0 score : 0.97\n",
            "# test episode 1 score : 0.98\n",
            "# test episode 2 score : 0.97\n",
            "# test episode 3 score : 0.97\n",
            "# test episode 4 score : 0.92\n",
            "# test episode 5 score : 0.88\n",
            "# test episode 6 score : 0.96\n",
            "# test episode 7 score : 1\n",
            "# test episode 8 score : 0.9299999999999999\n",
            "# test episode 9 score : 0.45999999999999974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/monitoring/video_recorder.py:59: UserWarning: \u001b[33mWARN: Disabling video recorder because environment <TimeLimit<OrderEnforcing<PassiveEnvChecker<GridWorldEnv<gym_examples/GridWorld-v0>>>>> was not initialized with any compatible video mode between `rgb_array` and `rgb_array_list`\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def display_video(episode=0):\n",
        "    mp4 = open(f'./video/rl-video-episode-{episode}.mp4','rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    HTML(\"\"\"\n",
        "    <video width=500 controls>\n",
        "          <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)"
      ],
      "metadata": {
        "id": "QVRSvhGwejw7"
      },
      "id": "QVRSvhGwejw7",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_video()"
      ],
      "metadata": {
        "id": "jA6-6MIXdSnB",
        "outputId": "d90017b6-149b-4359-8735-0f9cd7647d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "id": "jA6-6MIXdSnB",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7e2938b77132>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-bc4c8b64549e>\u001b[0m in \u001b[0;36mdisplay_video\u001b[0;34m(episode)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./video/rl-video-episode-{episode}.mp4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data:video/mp4;base64,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb64encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     HTML(\"\"\"\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './video/rl-video-episode-0.mp4'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}