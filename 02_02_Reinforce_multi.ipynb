{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e66c391",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/merucode/RL/blob/93-Project-Trader-Custom_enviromnet/02_Reinforce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0WrUPiyn7P_",
   "metadata": {
    "id": "w0WrUPiyn7P_"
   },
   "source": [
    "# To Do List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MLB979Vs-2J1",
   "metadata": {
    "id": "MLB979Vs-2J1"
   },
   "source": [
    "# Install Dependency and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bMkFjiRc-i71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "bMkFjiRc-i71",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c6aa879c-b973-4c9b-e445-18cc81d977af"
   },
   "outputs": [],
   "source": [
    "!git clone -b 93-Project-Trader-Custom_enviromnet https://github.com/merucode/RL.git\n",
    "!cd RL && mv * ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-fCSwqlbr0G0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-fCSwqlbr0G0",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0b9bf3bb-2605-477f-9f7c-38bd8ffbdb3c"
   },
   "outputs": [],
   "source": [
    "!pip install gym==0.25.2\n",
    "!pip install -e gym-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aI9PkFlbBds1",
   "metadata": {
    "id": "aI9PkFlbBds1"
   },
   "source": [
    "### NOTE: After inistall gym-examples, Restart runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wnV10JVAuKkv",
   "metadata": {
    "id": "wnV10JVAuKkv"
   },
   "source": [
    "# STEP. Ready Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lIdCfqT8uVFV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIdCfqT8uVFV",
    "outputId": "cd5abe2a-07e1-4ca6-f613-1d421999346b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              open        high         low       close    volume\n",
      "492909  39190000.0  39231000.0  39190000.0  39212000.0  2.929709\n",
      "492910  39212000.0  39214000.0  39188000.0  39191000.0  3.407502\n",
      "492911  39191000.0  39210000.0  39188000.0  39188000.0  3.884740\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('KRW-BTC_5m_171001_200903_upbit.csv')\n",
    "df2 = pd.read_csv('KRW-BTC_5m_200904_230810_upbit.csv')\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df = df[df.columns[1:]]\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Z-q3j3mOuX8U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-q3j3mOuX8U",
    "outputId": "b6380665-21bf-4e5f-c422-22be91a65308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          open    high     low   close    volume\n",
      "0        479.7   480.0   479.3   480.0  0.013444\n",
      "1        479.8   479.9   479.2   479.3  0.013597\n",
      "2        479.5   480.2   479.5   479.5  0.016304\n",
      "3        480.1   480.2   479.5   480.1  0.017136\n",
      "4        479.7   479.9   479.1   479.9  0.007615\n",
      "...        ...     ...     ...     ...       ...\n",
      "492907  3920.5  3920.8  3917.9  3920.6  2.508436\n",
      "492908  3920.6  3921.2  3918.6  3921.2  1.350777\n",
      "492909  3919.0  3923.1  3919.0  3921.2  2.929709\n",
      "492910  3921.2  3921.4  3918.8  3919.1  3.407502\n",
      "492911  3919.1  3921.0  3918.8  3918.8  3.884740\n",
      "\n",
      "[492912 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preporcessing df_render\n",
    "#df = df[:400000] #Temp : TEST\n",
    "df_ohlc = df[df.columns[:4]] / 10000\n",
    "df_v = df[df.columns[-1:]]\n",
    "df = pd.concat([df_ohlc, df_v], axis=1)\n",
    "df_render = df\n",
    "print(df_render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vwYc-64UCFMB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwYc-64UCFMB",
    "outputId": "058780e7-3628-4178-a45b-af1557fe5ed0"
   },
   "outputs": [],
   "source": [
    "# Preporcessing df\n",
    "df_ohlc = df[df.columns[:4]]\n",
    "df_ohlc_normalization = (df_ohlc - df_ohlc.mean())/df_ohlc.std()\n",
    "df_v = df[df.columns[-1:]]\n",
    "df_v_normalization =  (df_v - df_v.mean())/df_v.std()\n",
    "df = pd.concat([df_ohlc_normalization, df_v_normalization], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uDtueZp92Lyu",
   "metadata": {
    "id": "uDtueZp92Lyu",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qbiGRhuOuykv",
   "metadata": {
    "collapsed": true,
    "id": "qbiGRhuOuykv",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8jxMPAo5O7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d8jxMPAo5O7",
    "outputId": "8f99f283-0245-48fc-d767-7d8b84457f8b"
   },
   "outputs": [],
   "source": [
    "env = gym.vector.make(\"gym_examples:TradeWorld-v0\", num_envs=2, df=df, df_render=df_render, obs_len=2016)\n",
    "\n",
    "print(f'observation space        : {env.observation_space}')\n",
    "print(f\"observation single space : {env.single_observation_space.shape[0]}\")\n",
    "print(f'action space             : {env.action_space}')\n",
    "print(f'action single shape      : {env.single_action_space.n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e047cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset(return_info=True)\n",
    "print(obs)\n",
    "print(obs.shape)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = env.action_space.sample()\n",
    "print(actions)\n",
    "env.step(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a3c42",
   "metadata": {},
   "source": [
    "# STEP. Reinforce_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch-lightning==2.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0068f950",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\lightning_fabric\\__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\torchmetrics\\utilities\\imports.py:24: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _PYTHON_LOWER_3_8 = LooseVersion(_PYTHON_VERSION) < LooseVersion(\"3.8\")\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:242: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:286: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:319: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\pytorch_lightning\\__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import gym\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque, namedtuple\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import IterableDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "\n",
    "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, \\\n",
    "  NormalizeObservation, NormalizeReward\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "num_gpus = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1f1a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientPolicy(\n",
       "  (fc1): Linear(in_features=10080, out_features=5040, bias=True)\n",
       "  (fc2): Linear(in_features=5040, out_features=2520, bias=True)\n",
       "  (fc3): Linear(in_features=2520, out_features=1260, bias=True)\n",
       "  (fc4): Linear(in_features=1260, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GradientPolicy(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, n_actions, hidden_size=1260):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_size*4)\n",
    "        self.fc2 = nn.Linear(hidden_size*4, hidden_size*2)\n",
    "        self.fc3 = nn.Linear(hidden_size*2, hidden_size*1)\n",
    "        self.fc4 = nn.Linear(hidden_size*1, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x).float().to(device)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=-1)\n",
    "        return x\n",
    "\n",
    "policy = GradientPolicy(10080, 16)#GradientPolicy(env.single_observation_space.shape[0], env.single_action_space.n)\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7203172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(env_name, num_envs, **kwargs):\n",
    "    env = gym.vector.make(env_name, num_envs=num_envs, **kwargs)\n",
    "    env = RecordEpisodeStatistics(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c4c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLDataset(IterableDataset):\n",
    "\n",
    "    def __init__(self, env, policy, steps_per_epoch, gamma):\n",
    "        self.env = env\n",
    "        self.policy = policy\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.gamma = gamma\n",
    "        self.obs = env.reset()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __iter__(self):\n",
    "        transitions = []\n",
    "\n",
    "        for step in range(self.steps_per_epoch):\n",
    "            action = self.policy(self.obs)\n",
    "            action = action.multinomial(1).cpu().numpy()\n",
    "            next_obs, reward, done, info = self.env.step(action.flatten())\n",
    "            transitions.append((self.obs, action, reward, done))\n",
    "            self.obs = next_obs\n",
    "\n",
    "        obs_b, action_b, reward_b, done_b = map(np.stack, zip(*transitions))\n",
    "\n",
    "        running_return = np.zeros(self.env.num_envs, dtype=np.float32)\n",
    "        return_b = np.zeros_like(reward_b)\n",
    "\n",
    "        for row in range(self.steps_per_epoch - 1, -1, -1):\n",
    "            running_return = reward_b[row] + (1 - done_b[row]) * self.gamma * running_return\n",
    "            return_b[row] = running_return\n",
    "\n",
    "        num_samples = self.env.num_envs * self.steps_per_epoch\n",
    "        obs_b = obs_b.reshape(num_samples, -1)\n",
    "        action_b = action_b.reshape(num_samples, -1)\n",
    "        return_b = return_b.reshape(num_samples, -1)\n",
    "\n",
    "        idx = list(range(num_samples))\n",
    "        random.shuffle(idx)\n",
    "\n",
    "        for i in idx:\n",
    "            yield obs_b[i], action_b[i], return_b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c89cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reinforce(LightningModule):\n",
    "\n",
    "    def __init__(self, env_name, num_envs=8, samples_per_epoch=10, batch_size=2048,\n",
    "                hidden_size=1060, policy_lr=0.001, gamma=0.99, entropy_coef=0.001, optim=AdamW):\n",
    "\n",
    "        super().__init__()\n",
    "        self.training_step_outputs = []\n",
    "        self.env = create_env(env_name, num_envs=num_envs, df=df, df_render=df_render, obs_len=2016)\n",
    "\n",
    "        obs_size = self.env.single_observation_space.shape[0]\n",
    "        n_actions = self.env.single_action_space.n\n",
    "\n",
    "        self.policy = GradientPolicy(obs_size, n_actions, hidden_size)\n",
    "        self.dataset = RLDataset(self.env, self.policy, samples_per_epoch, gamma)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "\n",
    "    # Configure optimizers.\n",
    "    def configure_optimizers(self):\n",
    "        return self.hparams.optim(self.policy.parameters(), lr=self.hparams.policy_lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.dataset, batch_size=self.hparams.batch_size)\n",
    "\n",
    "    # Training step.\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        obs, actions, returns = batch\n",
    "        \n",
    "        probs = self.policy(obs)\n",
    "        log_probs = torch.log(probs + 1e-6)\n",
    "        action_log_prob = log_probs.gather(1, actions)\n",
    "\n",
    "        entropy = - torch.sum(probs * log_probs, dim=-1, keepdim=True)\n",
    "\n",
    "        pg_loss = - action_log_prob * returns\n",
    "        loss = (pg_loss - self.hparams.entropy_coef * entropy).mean()\n",
    "\n",
    "        self.log(\"episode/PG Loss\", pg_loss.mean())\n",
    "        self.log(\"episode/Entropy\", entropy.mean())\n",
    "        #self.log(\"episode/returns\", returns.mean())\n",
    "        self.training_step_outputs.append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "         epoch_average = torch.stack(self.training_step_outputs).mean()\n",
    "         self.log(\"training_epoch_average\", epoch_average)\n",
    "         self.training_step_outputs.clear()  # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4c5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "'rm'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16480), started 1:39:48 ago. (Use '!kill 16480' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d4081a531b6d5962\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d4081a531b6d5962\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -r /content/lightning_logs/\n",
    "!rm -r /content/videos/\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3967124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type           | Params\n",
      "------------------------------------------\n",
      "0 | policy | GradientPolicy | 54.0 M\n",
      "------------------------------------------\n",
      "54.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "54.0 M    Total params\n",
      "215.998   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 1it [00:00,  3.11it/s, v_num=9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kym92\\AppData\\Local\\Temp\\ipykernel_2032\\3842473335.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: : 1it [00:00,  3.79it/s, v_num=9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: : 1it [00:02,  2.26s/it, v_num=9]\n"
     ]
    }
   ],
   "source": [
    "algo = Reinforce('gym_examples:TradeWorld-v0')\n",
    "\n",
    "trainer = Trainer(\n",
    "  devices=num_gpus,\n",
    "  accelerator=\"gpu\",\n",
    "  max_epochs=300,\n",
    "  log_every_n_steps=1\n",
    ")\n",
    "\n",
    "trainer.fit(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f4ce572",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(algo.policy.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vbjOC1aG60ss",
   "metadata": {
    "id": "vbjOC1aG60ss"
   },
   "source": [
    "# STEP. Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "T2HdDgxC63Bp",
   "metadata": {
    "id": "T2HdDgxC63Bp"
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "def model_render(env_name, **kwargs):\n",
    "    env = gym.make(env_name, **kwargs)\n",
    "    episode_trigger=lambda e: True  # all Episode Recode\n",
    "\n",
    "    env = gym.wrappers.RecordVideo(env, \"./video\", episode_trigger=episode_trigger, video_length=100000)\n",
    "\n",
    "    for episode in range(1):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        pi = GradientPolicy(10080, 16, hidden_size=1060)\n",
    "        pi.load_state_dict(torch.load('model_weights.pth'))\n",
    "        pi.eval()\n",
    "\n",
    "        pi.to(device)\n",
    "\n",
    "        while not done:\n",
    "            prob = pi(torch.from_numpy(s).float().to(device))\n",
    "            m = Categorical(prob)\n",
    "            a = m.sample()\n",
    "            s_prime, r, done, info = env.step(a.item())\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            s = s_prime\n",
    "            score += r\n",
    "            #print(f\"DEBUG balance: {info['balance']}, {a.item()}\")\n",
    "\n",
    "        print(f\"# of episode {episode}:, avg score : {score}\")\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "kEE622ejAzBu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEE622ejAzBu",
    "outputId": "f5fb55bb-1779-4fee-9024-3dfc441bafa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231: : 1it [15:32, 932.71s/it, v_num=8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\wrappers\\record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\kym92\\project\\trader\\02_custom_environment\\video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: float32\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment TradeWorld-v0 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "C:\\Users\\kym92\\AppData\\Local\\Temp\\ipykernel_2032\\3842473335.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float().to(device)\n",
      "c:\\Users\\kym92\\anaconda3\\envs\\trade_world\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:141: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "model_render(\"gym_examples:TradeWorld-v0\", df=df, df_render=df_render, obs_len=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AU3x9mfiA0tO",
   "metadata": {
    "id": "AU3x9mfiA0tO"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "mp4 = open('./video/rl-video-episode-0.mp4','rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(\"\"\"\n",
    "<video width=500 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nZLCQcp-AJsG",
   "metadata": {
    "id": "nZLCQcp-AJsG"
   },
   "source": [
    "# Test Code"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "trade_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
