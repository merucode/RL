{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/RL/blob/31-Colab-Study-Udemy-Custom_env/02_Applying_a_Custom_Environment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "humanitarian-ministry",
      "metadata": {
        "id": "humanitarian-ministry"
      },
      "source": [
        "___\n",
        "\n",
        "<a href='http://www.pieriandata.com'><img src='../Pierian_Data_Logo.png'/></a>\n",
        "___\n",
        "<center><em>Copyright by Pierian Data Inc.</em></center>\n",
        "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>\n",
        "\n",
        "# Applying a Custom Environment\n",
        "\n",
        "We've created a custom environment using OpenAI Gym, let's now explore how we would apply our Agent to it!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e2ab84",
      "metadata": {
        "id": "35e2ab84"
      },
      "source": [
        "**IMPORTANT NOTE! YOU NEED TO PIP INSTALL YOUR SNAKE FILE FIRST WITH:**\n",
        "\n",
        "    pip install -e snake\n",
        "    \n",
        "**YOU RUN THIS AT YOUR COMMAND LINE (MAKE SURE TO ACTIVATE ANY ENV YOU ARE USING) AT THE TOP LEVEL FOLDER, FOR OUR COURSE NOTES THIS WOULD BE \"07-Custom-RL\"**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc48265",
      "metadata": {
        "id": "fcc48265"
      },
      "source": [
        "-------------\n",
        "\n",
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apparent-forwarding",
      "metadata": {
        "id": "apparent-forwarding"
      },
      "outputs": [],
      "source": [
        "\n",
        "from PIL import Image  # To transform the image in the Processor\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Convolutional Backbone Network\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Keras-RL\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "small-kentucky",
      "metadata": {
        "id": "small-kentucky",
        "outputId": "9aa964c7-bee6-4e87-a01c-79552b79a9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.0.1 (SDL 2.0.14, Python 3.8.10)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"snake:snake-v0\")\n",
        "nb_actions = env.action_space.n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2828f516",
      "metadata": {
        "id": "2828f516"
      },
      "source": [
        "-----\n",
        "# Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3faa96",
      "metadata": {
        "id": "1e3faa96",
        "outputId": "cd4f02f0-fc5d-402e-e42c-86bdff5278b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "divine-variable",
      "metadata": {
        "id": "divine-variable"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-trick",
      "metadata": {
        "id": "transsexual-trick"
      },
      "outputs": [],
      "source": [
        "class ImageProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        # First convert the numpy array to a PIL Image\n",
        "        img = Image.fromarray(observation)\n",
        "        # Then resize the image\n",
        "        img = img.resize(IMG_SHAPE)\n",
        "        # And convert it to grayscale  (The L stands for luminance)\n",
        "        img = img.convert(\"L\")\n",
        "        # Convert the image back to a numpy array and finally return the image\n",
        "        img = np.array(img)\n",
        "        return img.astype('uint8')  # saves storage in experience memory\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "\n",
        "        # We divide the observations by 255 to compress it into the intervall [0, 1].\n",
        "        # This supports the training of the network\n",
        "        # We perform this operation here to save memory.\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65983cf1",
      "metadata": {
        "id": "65983cf1"
      },
      "source": [
        "## Model Creation\n",
        "\n",
        "**NOTE: Depending on your custom environment, this model will vary greatly, try reading papers that are solving similar problems to your own!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "single-judges",
      "metadata": {
        "id": "single-judges",
        "outputId": "c68ff339-704d-4e18-c190-3176d31cd05e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 84, 84)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "another-jaguar",
      "metadata": {
        "id": "another-jaguar",
        "outputId": "b8dbbb9d-0bf5-4dc5-ded7-537795bc304e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "permute (Permute)            (None, 84, 84, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 20, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 1,686,180\n",
            "Trainable params: 1,686,180\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
        "\n",
        "model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(64, (4, 4), strides=(2, 2), kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(64, (3, 3), strides=(1, 1), kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6601e15b",
      "metadata": {
        "id": "6601e15b"
      },
      "source": [
        "----\n",
        "## Creating the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "magnetic-scholar",
      "metadata": {
        "id": "magnetic-scholar"
      },
      "outputs": [],
      "source": [
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-sacramento",
      "metadata": {
        "id": "happy-sacramento"
      },
      "outputs": [],
      "source": [
        "processor = ImageProcessor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upper-sport",
      "metadata": {
        "id": "upper-sport"
      },
      "outputs": [],
      "source": [
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
        "                              nb_steps=1000000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "southeast-constant",
      "metadata": {
        "id": "southeast-constant"
      },
      "outputs": [],
      "source": [
        "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
        "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
        "              train_interval=4, delta_clip=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respiratory-sense",
      "metadata": {
        "id": "respiratory-sense"
      },
      "outputs": [],
      "source": [
        "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "modified-tract",
      "metadata": {
        "id": "modified-tract"
      },
      "outputs": [],
      "source": [
        "weights_filename = 'test_dqn_snake_weights.h5f'\n",
        "checkpoint_weights_filename = 'test_dqn_' + \"snake\" + '_weights_{step}.h5f'\n",
        "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "present-graduate",
      "metadata": {
        "id": "present-graduate",
        "outputId": "523d40cc-ccb6-4689-bf4e-a4221f885f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 1500000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "    31/100000 [..............................] - ETA: 5:48 - reward: 0.0000e+00  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100000/100000 [==============================] - 1235s 12ms/step - reward: -0.0204\n",
            "2264 episodes - episode_reward: -0.903 [-1.000, 2.000] - loss: 0.003 - mae: 0.142 - mean_q: 0.187 - mean_eps: 0.932 - score: 0.077\n",
            "\n",
            "Interval 2 (100000 steps performed)\n",
            "   457/100000 [..............................] - ETA: 35:24 - reward: -0.0131done, took 1245.677 seconds\n"
          ]
        }
      ],
      "source": [
        "dqn.fit(env, nb_steps=1500000, callbacks=[checkpoint_callback], log_interval=100000, visualize=False)\n",
        "\n",
        "# After training is done, we save the final weights one more time.\n",
        "dqn.save_weights(weights_filename, overwrite=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bronze-discount",
      "metadata": {
        "id": "bronze-discount"
      },
      "outputs": [],
      "source": [
        "# Load the weights\n",
        "model.load_weights(\"test_dqn_snake_weights.h5f\")\n",
        "\n",
        "\n",
        "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1, value_min=.1, value_test=.05,\n",
        "                              nb_steps=100000)\n",
        "\n",
        "processor = ImageProcessor()\n",
        "\n",
        "# Initialize the DQNAgent with the new model and updated policy and compile it\n",
        "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
        "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000)\n",
        "dqn.compile(Adam(learning_rate=.00025), metrics=['mae'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "antique-stability",
      "metadata": {
        "id": "antique-stability"
      },
      "outputs": [],
      "source": [
        "env.sleep = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acute-florence",
      "metadata": {
        "id": "acute-florence",
        "outputId": "9deb6955-0c8e-42ef-f305-4ba56fc031d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 1 episodes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Marcial\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1: reward: -1.000, steps: 43\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1c94a9cf0d0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dqn.test(env, nb_episodes=1, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "encouraging-reynolds",
      "metadata": {
        "id": "encouraging-reynolds"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}